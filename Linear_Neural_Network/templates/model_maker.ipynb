{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from numpy import array\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch version:\")\n",
    "print(torch.__version__)\n",
    "print(\"GPU Detected:\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Neural Network class\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"[Linear Neural Network Model Generator]\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, num_hidden, hidden_dim, dropout):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            input_size ([int]): [number of input features]\n",
    "            num_hidden ([int]): [number of hidden layers]\n",
    "            hidden_dim ([int]): [hidden layer dimension]\n",
    "            dropout (float): [dropout rate].\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList([])\n",
    "        self.hidden_layers.append(nn.Linear(input_size, hidden_dim))\n",
    "        for i in range(num_hidden - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_projection = nn.Linear(hidden_dim, 1)\n",
    "        self.nonlinearity = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"[Forward for Neural network]\n",
    "\n",
    "        Args:\n",
    "            x ([Tensor]): [input tensor for raw values]\n",
    "        Returns:\n",
    "            [Tensor]: [output results from model]\n",
    "        \"\"\"\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = hidden_layer(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.nonlinearity(x)\n",
    "        out = self.output_projection(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the class with params and move it to GPU if available\n",
    "newmodel = MLP(856, 3, 256, 0.5).double()\n",
    "newmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files from the train split\n",
    "files=pd.read_json('../../train_files_801010.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the input features and the labels in the train set\n",
    "def split_sequences(sequences):\n",
    "    \"\"\"[inputs a numpy array]\n",
    "    Args:\n",
    "        sequences ([np.array]): [numpy array of data]\n",
    "\n",
    "    Returns:\n",
    "        x [np.array]: [returns a numpy array of features]\n",
    "        y [np.array]: [returns a numpy array of labels]\n",
    "    \"\"\"\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + 1\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training files into a train set and val set\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "train_set=random.choices(list(files[0]),k=int(len(files)*0.8))\n",
    "val_set=list(set(files[0])-set(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "numberepochs=10\n",
    "breakpoint=50\n",
    "criterion = torch.nn.MSELoss() # reduction='sum' created huge loss value\n",
    "optimizer = torch.optim.Adam(newmodel.parameters(), lr=1e-1)\n",
    "train_episodes = 500\n",
    "batch_size = 100\n",
    "epochs = 1\n",
    "counter = 0\n",
    "print_every = 50\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "# training the model over 10 epochs\n",
    "for i in range(numberepochs):\n",
    "    epoch_train=random.choices(train_set,k=750*8)\n",
    "    epoch_val=random.choices(val_set,k=750*2)\n",
    "\n",
    "\n",
    "    for number in range(int(750*8/breakpoint)):\n",
    "        trainingnp_x= np.empty((0,1,856), int)\n",
    "        trainingnp_y= np.empty((0,), int)\n",
    "        startno=number*50\n",
    "        for i in tqdm(epoch_train[startno:startno+50]):\n",
    "            joineddf=pd.read_feather('../../processed3-edited/'+i)\n",
    "            joineddf=joineddf.fillna(0)\n",
    "            tnp=joineddf[[c for c in joineddf if c not in ['Retweets']] \n",
    "                   + ['Retweets']].to_numpy()\n",
    "            trainingnpx,trainingnpy=split_sequences(tnp)\n",
    "\n",
    "            trainingnp_x = np.append(trainingnp_x, trainingnpx, axis=0)\n",
    "            trainingnp_y = np.append(trainingnp_y, trainingnpy, axis=0)\n",
    "\n",
    "        valnp_x= np.empty((0,1,856), int)\n",
    "        valnp_y= np.empty((0,), int)\n",
    "        for i in tqdm(epoch_val[startno:startno+50]):\n",
    "            joineddf=pd.read_feather('../../processed3-edited/'+i)\n",
    "            joineddf=joineddf.fillna(0)\n",
    "            vnp=joineddf[[c for c in joineddf if c not in ['Retweets']] \n",
    "                   + ['Retweets']].to_numpy()\n",
    "            valnpx,valnpy=split_sequences(tnp)\n",
    "\n",
    "            valnp_x = np.append(valnp_x, valnpx, axis=0)\n",
    "            valnp_y = np.append(valnp_y, valnpy, axis=0)\n",
    "        train_data = TensorDataset(torch.from_numpy(trainingnp_x), torch.from_numpy(trainingnp_y))\n",
    "        val_data = TensorDataset(torch.from_numpy(valnp_x), torch.from_numpy(valnp_y))\n",
    "\n",
    "        train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size)\n",
    "        val_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "        newmodel.train()\n",
    "        for i in range(epochs):\n",
    "            for inputs, labels in train_loader:\n",
    "                counter += 1\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                newmodel.zero_grad()\n",
    "                output = newmodel(inputs)\n",
    "                loss = criterion(output.squeeze(), labels)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(newmodel.parameters(), clip)\n",
    "                optimizer.step()\n",
    "                \n",
    "                # compare against the validation split at the step_size (print_every), to check for improvement\n",
    "                if counter%print_every == 0:\n",
    "                    val_losses = []\n",
    "                    newmodel.eval()\n",
    "                    for inp, lab in val_loader:\n",
    "                        inp, lab = inp.to(device), lab.to(device)\n",
    "                        out = newmodel(inp)\n",
    "                        val_loss = criterion(out.squeeze(), lab)\n",
    "                        val_losses.append(val_loss.item())\n",
    "\n",
    "                    newmodel.train()\n",
    "                    # slight mistake here, epochs will print as 1/1 always, because of i at the closest parent loop, but in fact it actually runs for 10 epochs as intended\n",
    "                    print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                          \"Step: {}...\".format(counter),\n",
    "                          \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                          \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "                    # if there is a improvement save the model\n",
    "                    if np.mean(val_losses) <= valid_loss_min:\n",
    "                        torch.save(newmodel.state_dict(), './state_dict_1.pt')\n",
    "                        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                        valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(newmodel.state_dict(), './state_dict_2.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
