{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.metrics import mean_squared_log_error\r\n",
    "import torch.nn as nn\r\n",
    "from torch.utils.data import TensorDataset, DataLoader\r\n",
    "import torch\r\n",
    "import pandas as pd\r\n",
    "from numpy import array\r\n",
    "from tqdm import tqdm\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "files=pd.read_json('test_files_801010.json')\r\n",
    "# change path to reflect where the data is \r\n",
    "#and which data you are testing"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "len(files)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19967"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "is_cuda = torch.cuda.is_available()\r\n",
    "\r\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\r\n",
    "if is_cuda:\r\n",
    "    device = torch.device(\"cuda\")\r\n",
    "else:\r\n",
    "    device = torch.device(\"cpu\")\r\n",
    "\r\n",
    "def modelload(param,path_to_model):\r\n",
    "    \"\"\"[loads model for testing]\r\n",
    "\r\n",
    "    Args:\r\n",
    "        param ([list]): [list of parameters to fit into model for the models dimensions]\r\n",
    "        path_to_model ([string]): [path to model that is being tested]\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        [nn.Module]: [loaded model with pretrained weights]\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    class GenModel(nn.Module):\r\n",
    "        \"\"\"[LSTM Model Generator]\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        def __init__(self, hidden_dim,seq_length, n_layers,hidden_layers,\r\n",
    "                    bidirectional, dropout=0.5):\r\n",
    "            \"\"\"[summary]\r\n",
    "\r\n",
    "            Args:\r\n",
    "                hidden_dim ([List]): [list of integers for dimensions of hidden layers]\r\n",
    "                seq_length ([int]): [window size of 1 reading]\r\n",
    "                n_layers ([int]): [description]\r\n",
    "                hidden_layers ([int]): [description]\r\n",
    "                bidirectional ([boolean]): [boolean of whether the bidirectional ]\r\n",
    "                dropout (float, optional): [description]. Defaults to 0.5.\r\n",
    "            \"\"\"\r\n",
    "            super().__init__()\r\n",
    "            self.rnn = nn.LSTM(856, \r\n",
    "                            hidden_dim[0], \r\n",
    "                            num_layers=n_layers, #set to two: makes our LSTM 'deep'\r\n",
    "                            bidirectional=bidirectional, #bidirectional or not\r\n",
    "                            dropout=dropout,batch_first=True) #we add dropout for regularization\r\n",
    "            \r\n",
    "            if bidirectional:\r\n",
    "                self.D=2\r\n",
    "            else:\r\n",
    "                self.D=1\r\n",
    "            self.n_layers=n_layers\r\n",
    "            self.hidden_dim=hidden_dim[0]\r\n",
    "            self.nonlinearity = nn.ReLU() \r\n",
    "            self.hidden_layers = nn.ModuleList([])\r\n",
    "            self.seq_length=seq_length\r\n",
    "            self.dropout=nn.Dropout(dropout)\r\n",
    "            assert(len(hidden_dim)>0)\r\n",
    "            assert(len(hidden_dim)==1+hidden_layers)\r\n",
    "\r\n",
    "            i=0\r\n",
    "            if hidden_layers>0:\r\n",
    "                self.hidden_layers.append(nn.Linear(hidden_dim[i]*self.D*self.seq_length, hidden_dim[i+1]))\r\n",
    "                for i in range(hidden_layers-1):\r\n",
    "                    self.hidden_layers.append(nn.Linear(hidden_dim[i+1], hidden_dim[i+2]))\r\n",
    "                self.output_projection = nn.Linear(hidden_dim[i+1], 1)\r\n",
    "            else:\r\n",
    "                self.output_projection = nn.Linear(hidden_dim[i]*self.D*self.seq_length, 1)\r\n",
    "        \r\n",
    "            \r\n",
    "            \r\n",
    "        def forward(self, x,hidden):\r\n",
    "            \"\"\"[Forward for Neural network]\r\n",
    "\r\n",
    "            Args:\r\n",
    "                x ([Tensor]): [input tensor for raw values]\r\n",
    "                hidden ([Tensor]): [hidden state values for lstm model]\r\n",
    "\r\n",
    "            Returns:\r\n",
    "                [Tensor]: [output results from model]\r\n",
    "            \"\"\"\r\n",
    "            \r\n",
    "            batch_size= x.size(0)\r\n",
    "\r\n",
    "            val, hidden = self.rnn(x,hidden) #feed to rnn\r\n",
    "            \r\n",
    "            #unpack sequence\r\n",
    "            val = val.contiguous().view( batch_size,-1)\r\n",
    "            for hidden_layer in self.hidden_layers:\r\n",
    "                val = hidden_layer(val)\r\n",
    "                val = self.dropout(val)\r\n",
    "                val = self.nonlinearity(val) \r\n",
    "            out = self.output_projection(val)\r\n",
    "\r\n",
    "            return out,hidden\r\n",
    "        \r\n",
    "        \r\n",
    "        def init_hidden(self, batch_size):\r\n",
    "            \"\"\"[summary]\r\n",
    "\r\n",
    "            Args:\r\n",
    "                batch_size ([int]): [size of batch that you are inputting into the model]\r\n",
    "\r\n",
    "            Returns:\r\n",
    "                [Tensor]: [Returns a tensor with the dimensions equals to the dimensions of the model's\r\n",
    "                hidden state with values 0]\r\n",
    "            \"\"\"\r\n",
    "            weight = next(self.parameters()).data\r\n",
    "            hidden = (weight.new(self.n_layers*self.D, batch_size, self.hidden_dim).zero_().to(device),\r\n",
    "                        weight.new(self.n_layers*self.D, batch_size, self.hidden_dim).zero_().to(device))\r\n",
    "            \r\n",
    "            return hidden\r\n",
    "\r\n",
    "\r\n",
    "    newmodel = GenModel(param[0],param[1],param[2],param[3],param[4]).double()\r\n",
    "    newmodel.to(device)\r\n",
    "    newmodel.load_state_dict(torch.load(path_to_model))\r\n",
    "    return newmodel\r\n",
    "\r\n",
    "\r\n",
    " \r\n",
    "   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def split_sequences(sequences, n_steps):\r\n",
    "    \"\"\"[inputs a numpy array and outputs a windowed sequence to put into lstm model]\r\n",
    "\r\n",
    "    Args:\r\n",
    "        sequences ([np.array]): [numpy array of data to be sequenced into windows]\r\n",
    "        n_steps ([int]): [window size for the model]\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        [np.array]: [returns a numpy array with data sequenced into windows of size n_steps]\r\n",
    "    \"\"\"\r\n",
    "    X, y = list(), list()\r\n",
    "    for i in range(len(sequences)):\r\n",
    "        # find the end of this pattern\r\n",
    "        end_ix = i + n_steps\r\n",
    "        # check if we are beyond the dataset\r\n",
    "        if end_ix > len(sequences):\r\n",
    "            break\r\n",
    "        # gather input and output parts of the pattern\r\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\r\n",
    "        X.append(seq_x)\r\n",
    "        y.append(seq_y)\r\n",
    "    return array(X), array(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "newmodel= modelload(([256], 30,2, 0, True,0.5),'./state_dict_11.pt')\r\n",
    "newmodel.eval()\r\n",
    "stepsize=40\r\n",
    "\r\n",
    "n_timesteps=30\r\n",
    "batch_size = 100-n_timesteps+1\r\n",
    "epoch_val=files[0]\r\n",
    "epoch_size=len(files[0])\r\n",
    "listmean=[]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "\r\n",
    "for number in tqdm(range(int(epoch_size/stepsize))):\r\n",
    "    val_x= np.empty((0,n_timesteps,856), int)\r\n",
    "    val_y= np.empty((0,), int)\r\n",
    "    startno=number*stepsize\r\n",
    "    for i in (epoch_val[startno:startno+stepsize]):\r\n",
    "        joineddf=pd.read_feather('processed3-edited/'+i)\r\n",
    "        joineddf=joineddf.fillna(0)\r\n",
    "        tnp=joineddf[[c for c in joineddf if c not in ['Retweets']] \r\n",
    "               + ['Retweets']].to_numpy()\r\n",
    "        valnpx,valnpy=split_sequences(tnp, n_timesteps)\r\n",
    "\r\n",
    "        val_x = np.append(val_x, valnpx, axis=0)\r\n",
    "        val_y = np.append(val_y, valnpy, axis=0)\r\n",
    "    val_x=torch.Tensor(val_x).double().to(device)\r\n",
    "    h = newmodel.init_hidden(val_x.size()[0])\r\n",
    "    hcon = tuple([e.data for e in h])\r\n",
    "    predictions = newmodel(val_x,hcon)\r\n",
    "    listmean.append(mean_squared_log_error(val_y, predictions[0].cpu().detach().numpy().clip(min=0)))\r\n",
    "    predictions=[]\r\n",
    "    #only used to store intermediate predictions\r\n",
    "    # pd.DataFrame(listmean).to_csv('./test/mean'+str(number)+'.csv')    \r\n",
    "           "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 499/499 [1:45:02<00:00, 12.63s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "np.mean(listmean) #MSLE score"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.798414006329342"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('sml': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "interpreter": {
   "hash": "85b4babc1cb929d857a95535fce1522af1557ea7a1f56d14a49c79969786909b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}