{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=pd.read_json('../../test_files_801010.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "def modelload(param,path_to_model):\n",
    "    \"\"\"[Loads an existing model]\n",
    "\n",
    "    Args:\n",
    "        param ([Tuple]): [parameters for the model]\n",
    "        path_to_model ([String]): [filepath to previously saved model]\n",
    "    Returns:\n",
    "        [Tensor]: [output results from model]\n",
    "    \"\"\"\n",
    "    class MLP(nn.Module):\n",
    "        \"\"\"[Linear Neural Network Model Generator]\n",
    "\n",
    "        \"\"\"\n",
    "        def __init__(self, input_size, num_hidden, hidden_dim, dropout):\n",
    "            \"\"\"[initialise the model class]\n",
    "\n",
    "            Args:\n",
    "                input_size ([int]): [number of input features]\n",
    "                num_hidden ([int]): [number of hidden layers]\n",
    "                hidden_dim ([int]): [hidden layer dimension]\n",
    "                dropout (float): [dropout rate].\n",
    "            \"\"\"\n",
    "            super(MLP, self).__init__()\n",
    "            self.hidden_layers = nn.ModuleList([])\n",
    "            self.hidden_layers.append(nn.Linear(input_size, hidden_dim))\n",
    "            for i in range(num_hidden - 1):\n",
    "                self.hidden_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "            self.output_projection = nn.Linear(hidden_dim, 1)\n",
    "            self.nonlinearity = nn.ReLU()\n",
    "\n",
    "        def forward(self, x):\n",
    "            \"\"\"[Forward for Neural network]\n",
    "\n",
    "            Args:\n",
    "                x ([Tensor]): [input tensor for raw values]\n",
    "            Returns:\n",
    "                [Tensor]: [output results from model]\n",
    "            \"\"\"\n",
    "            for hidden_layer in self.hidden_layers:\n",
    "                x = hidden_layer(x)\n",
    "                x = self.dropout(x)\n",
    "                x = self.nonlinearity(x)\n",
    "            out = self.output_projection(x)\n",
    "            return out\n",
    "        \n",
    "    newmodel = MLP(param[0],param[1],param[2],param[3]).double()\n",
    "    newmodel.to(device)\n",
    "    newmodel.load_state_dict(torch.load(path_to_model))\n",
    "    return newmodel\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences):\n",
    "    \"\"\"[inputs a numpy array]\n",
    "    Args:\n",
    "        sequences ([np.array]): [numpy array of data]\n",
    "\n",
    "    Returns:\n",
    "        x [np.array]: [returns a numpy array of features]\n",
    "        y [np.array]: [returns a numpy array of labels]\n",
    "    \"\"\"\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + 1\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel= modelload((856, 3, 256, 0.5),'./model3/state_dict_3.pt')\n",
    "newmodel.eval()\n",
    "stepsize=40\n",
    "\n",
    "n_timesteps=30\n",
    "batch_size = 100\n",
    "epoch_test=files[0]\n",
    "epoch_size=len(files[0])\n",
    "listmean=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in tqdm(range(int(epoch_size/stepsize))):\n",
    "    test_x= np.empty((0,1,856), int)\n",
    "    test_y= np.empty((0,), int)\n",
    "    startno=number*stepsize\n",
    "    for i in (epoch_test[startno:startno+stepsize]):\n",
    "        joineddf=pd.read_feather('../../processed3-edited/'+i)\n",
    "        joineddf=joineddf.fillna(0)\n",
    "        tnp=joineddf[[c for c in joineddf if c not in ['Retweets']] \n",
    "               + ['Retweets']].to_numpy()\n",
    "        testnpx,testnpy=split_sequences(tnp)\n",
    "\n",
    "        test_x = np.append(test_x, testnpx, axis=0)\n",
    "        test_y = np.append(test_y, testnpy, axis=0)\n",
    "    \n",
    "    test_x=torch.Tensor(test_x).double().to(device)\n",
    "    predictions = newmodel(test_x)\n",
    "    listmean.append(mean_squared_log_error(test_y, predictions.cpu().detach().numpy().clip(min=0).squeeze()))\n",
    "    pd.DataFrame(listmean).to_csv('./best_linear_model/mean'+str(number)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(listmean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
